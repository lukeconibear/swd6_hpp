{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b05fc18-8748-41aa-b795-f1364eaf9acd",
   "metadata": {},
   "source": [
    "# Parallelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c590ffe-72a8-4f07-8a1d-0b3094b1d315",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/swd6_hpp/blob/main/docs/06_parallelisation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1b046-1d41-480f-b464-30c5aa65d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install dask[dataframe] joblib ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb26f9-e07f-46af-a1f4-e8d03138a9dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## What is it?\n",
    "\n",
    "Parallelisation divides a large problem into many smaller ones and solves them *simultaneously*.\n",
    "- *Divides up the time/space complexity across workers.*\n",
    "- Tasks centrally managed by a scheduler.\n",
    "- Multi-processing (cores)\n",
    "    - Useful for compute-bound problems.\n",
    "    - Overcomes the [Global Interpreter Lock, GIL](https://wiki.python.org/moin/GlobalInterpreterLock) (prevents running the bytecode on mutliple threads simutaneously).  \n",
    "    - Lower performance when need to exchange/aggregate data\n",
    "- Multi-threading (parts of processes)\n",
    "    - Useful for memory-bound problems.  \n",
    "    \n",
    "Parallelised code often introduces overheads. So, the speed-up benefits are more pronounced with bigger jobs, rather than some of the small examples used in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c09f95-164c-42fb-bb5e-65b632353227",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parallelising a Python?\n",
    "\n",
    "Python itself is not designed for massive scalability and controls threads preemptively using the GIL. This has lead many libraries to work around this using C/C++ backends.  \n",
    "\n",
    "Some options include:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2f939-6b83-4368-a790-e523f830d7c2",
   "metadata": {},
   "source": [
    "[multiprocessing](https://docs.python.org/3/library/multiprocessing.html) for creating a pool of asynchronous workers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735fffb-03cc-4645-8021-79f0b526c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def my_function(x):\n",
    "    return x * x\n",
    "\n",
    "with Pool(3) as workers:\n",
    "    print(workers.map(my_function, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d1f6a-25ee-48e2-ba15-312647c16007",
   "metadata": {},
   "source": [
    "[joblib](https://joblib.readthedocs.io/en/latest/) for creating lightweight pipelines that help with \"embaressingly parallel\" tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489f601-410e-4730-9bfc-0034471e6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e6016-8fd7-4ece-9c4c-b14c55d0d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.Parallel(n_jobs=1)(\n",
    "    joblib.delayed(math.sqrt)(i**2) for i in range(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8264d7-b205-4a05-9f15-e3fe80c17532",
   "metadata": {},
   "source": [
    "[asyncio](https://docs.python.org/3/library/asyncio.html) for concurrent programs, especially ones that are IO-bound.  \n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    print('Hello ...')\n",
    "    await asyncio.sleep(1)\n",
    "    print('... World!')\n",
    "    \n",
    "asyncio.run(main())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d15a9-431d-4356-a71b-962cd45de919",
   "metadata": {},
   "source": [
    "These options work well for the CPU cores on your machine, though not really beyond that.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa323619-ca8d-4baf-b261-41822de65db4",
   "metadata": {},
   "source": [
    "## [Dask](https://docs.dask.org/en/latest/)\n",
    "\n",
    "- Great features.\n",
    "- Helpful documentation.\n",
    "- Familiar API.\n",
    "- Under the hood for many libraries e.g. [xarray](http://xarray.pydata.org/en/stable/dask.html), [iris](https://scitools.org.uk/iris/docs/v2.4.0/userguide/real_and_lazy_data.html), [scikit-learn](https://ml.dask.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d190ba5-8dd6-479e-9302-2d54218f2547",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [Single machine](https://docs.dask.org/en/latest/setup/single-distributed.html)\n",
    "\n",
    "See the excellent video from Dask creator, Matthew Rocklin, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe580d-24d3-4c68-b2ea-76cdc1e35290",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://www.youtube.com/embed/ods97a5Pzw0', width='560', height='315')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba8c55-a3a1-429b-8a14-64082ab7e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    from dask.distributed import Client\n",
    "    client = Client()\n",
    "    client "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248ae5b-1a0f-4e21-a673-88820b089e28",
   "metadata": {},
   "source": [
    "If want multiple threads, then could use keyword arguments in Client instance:\n",
    "```python\n",
    "client = Client(processes=False, threads_per_worker=4, n_workers=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395bb449-ebc8-4e9d-a1f5-6de7b7b76702",
   "metadata": {},
   "source": [
    "Remember (important), always need to close down the client at the end:\n",
    "```python\n",
    "client.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e9e9b-83a5-43f9-b362-0e7dbb49c49f",
   "metadata": {},
   "source": [
    "### Dask behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11d37d-da70-4b7b-a96d-5f2b14a87936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdae6a8-2b7b-448c-bf63-cf2a6a7e2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.open_dataset(\n",
    "    'air_temperature',\n",
    "    chunks={'time': 'auto'} # dask chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e895d-8c79-40fa-8142-49315f8e737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean = ds.mean()\n",
    "ds_mean # a dask.array (an unexecuted task graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc51a6-be50-42ab-8f49-ffeba6959653",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d899e-3204-4f6d-9ff6-3c373816ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336846e-6d68-4fb8-a984-08da52783304",
   "metadata": {},
   "source": [
    "### [dask.array](https://examples.dask.org/array.html) (NumPy)\n",
    "See the excellent video from Dask creator, Matthew Rocklin, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1fe62-6ef0-4d93-9f21-755581fbd7e7",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://www.youtube.com/embed/ZrP-QTxwwnU', width='560', height='315')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957233c-9915-42a6-acc2-fe4e44dbd499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a19fd6-f8b7-460c-907a-9a9bf6da017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = da.random.random(\n",
    "    (5_000, 5_000),\n",
    "    chunks=(500, 500) # dask chunks\n",
    ")\n",
    "result = my_array + my_array.T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e56303-36e0-4315-93cb-0bae62a779d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e22457-c5da-4cae-8630-656e41c178cf",
   "metadata": {},
   "source": [
    "### [dask.dataframe](https://examples.dask.org/dataframe.html) (Pandas)\n",
    "See the excellent video from Dask creator, Matthew Rocklin, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b09b7a-0074-44ce-bc8d-9381941aa76e",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "IFrame(src='https://www.youtube.com/embed/6qwlDc959b0', width='560', height='315')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be313ba8-8bc0-448c-b2ff-1e7d03a82470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872db13-89b2-4bae-9095-eec4e0374355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask.datasets.timeseries()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270f5a1-0cc0-448f-bae3-9152a965ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eda54c-5add-4220-9384-363481bccadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.groupby('name').x.std()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb38f5-18c6-4885-b328-655a20181a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93ced4-6be9-4e22-8611-3ecb3d1b1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_computed = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f988a7-0f86-4acf-93f2-6e242ec79c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a2bea-f6c7-4426-aa74-46274fbb339b",
   "metadata": {},
   "source": [
    "### [dask.bag](https://examples.dask.org/bag.html)\n",
    "Iterate over a bag of independent objects (embarrassingly parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b9b4e-db14-4312-bbc2-7e98a002d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea84bb0-c031-4c81-9ed8-cce667e4de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = np.random.randint(low=0, high=100, size=(5_000))\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89c351-165c-4b5c-a30f-e8e33dca89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(nums):\n",
    "    return chr(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371db54a-453f-4479-9e83-4dca896b9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    bag = db.from_sequence(nums)\n",
    "    bag = bag.map(function)\n",
    "    \n",
    "    result = bag.compute()\n",
    "    \n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc84ee4-b552-4c3e-93e8-00778dbc6457",
   "metadata": {},
   "source": [
    "### [Dask on HPC](https://docs.dask.org/en/latest/setup/hpc.html)\n",
    "\n",
    "- Create/edit the [`dask_on_hpc.py`](https://github.com/lukeconibear/swd6_hpp/blob/main/docs/dask_on_hpc.py) file.\n",
    "- Submit to the queue using [`qsub dask_on_hpc.bash`](https://github.com/lukeconibear/swd6_hpp/blob/main/docs/dask_on_hpc.bash).\n",
    "\n",
    "If need to share memory across chunks:  \n",
    "- Use [shared memory](https://docs.dask.org/en/latest/shared.html) (commonly OpenMP, Open Multi-Processing).\n",
    "- `-pe smp np` on ARC4\n",
    "\n",
    "Otherwise:  \n",
    "- Use [message passing interface, MPI](https://docs.dask.org/en/latest/setup/hpc.html?highlight=mpi#using-mpi) (commonly OpenMPI).\n",
    "- `-pe ib np` on ARC4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddfeac-ddd8-4380-b817-b893effe6831",
   "metadata": {},
   "source": [
    "## [Ray](https://www.ray.io/)\n",
    "Ray will automatically detect the available GPUs and CPUs on the machine.\n",
    "- Can also [specify required resources](https://docs.ray.io/en/latest/walkthrough.html#specifying-required-resources)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449c4d4-bf18-46c4-a572-8d8e957c1674",
   "metadata": {},
   "source": [
    "First, initialise Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305875bc-134a-4f22-80ed-a0117345ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be24a6-c056-4013-8dc8-41f204c7e421",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions become Tasks\n",
    "- Parallelise functions by adding `@ray.remote` decorator  \n",
    "- Then instead of calling it normally, use the `.remote()` method  \n",
    "- This yields a future object reference that you can retrieve with `ray.get(object)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39f660-734d-4b53-84a7-3b8c8df07f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3454321-f0c0-4d61-ad32-00e29f21f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asynchronously run a task\n",
    "futures = [f.remote(i) for i in range(4)]\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb9d5a-64bb-4b42-a06e-52e20e8fb74b",
   "metadata": {},
   "source": [
    "### Classes become Actors\n",
    "- Parallelise classes the same way\n",
    "- These actors maintain their internal state  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b3e05-e18a-4a19-bbba-17159ac6a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        \n",
    "    def increment(self):\n",
    "        self.value += 1\n",
    "    \n",
    "    def read(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037ffcb-dccd-408b-bcf7-2df61e337905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an actor instance using .remote()\n",
    "counters = [Counter.remote() for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0a7b5-6b32-4238-ba7b-1e4005837f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asynchronously run actor methods\n",
    "[counter.increment.remote() for counter in counters]\n",
    "futures = [counter.read.remote() for counter in counters]\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a0190-d4b4-488e-bbb1-1a79bf5b07b4",
   "metadata": {},
   "source": [
    "Other key API methods:\n",
    "- `ray.put()`\n",
    "    - Put a value in the distributed object store.\n",
    "    - `put_id = ray.put(my_object)`\n",
    "- `ray.get()`\n",
    "    - Get an object from the distributed object store, either placed there by `ray.put()` explicitly or by a task or actor method, blocking until object is available.\n",
    "    - `thing = ray.get(put_id)`\n",
    "- `ray.wait()`\n",
    "    - Wait on a list of ids until one of the corresponding objects is available (e.g., the task completes). Return two lists, one with ids for the available objects and the other with ids for the still-running tasks or method calls.\n",
    "    `finished, running = ray.wait([train_id, track_id])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff7718-e93c-497d-90bf-8da746d31add",
   "metadata": {},
   "source": [
    "### Ray's [`multiprocessing`](https://docs.ray.io/en/latest/multiprocessing.html)\n",
    "To scale beyond one machine and generally manage a pool of processes.  \n",
    "\n",
    "Replace:\n",
    "```python\n",
    "from multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "With:\n",
    "\n",
    "```python\n",
    "from ray.util.multiprocessing.pool import Pool\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3793a-c08f-4fbb-bbc7-074a8e309d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e6b75-ce18-4b02-b3db-0ad8fcad4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec938a-652c-4636-8da1-1a177eb989eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(2) as workers:\n",
    "    print(workers.map(my_function, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4457d7-d7b3-4364-8d71-40455a3bd225",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ray's [`joblib`](https://docs.ray.io/en/latest/joblib.html)\n",
    "The underpinnings of [scikit-learn](https://scikit-learn.org/stable/), which Ray can scale to a cluster.\n",
    "\n",
    "Import and instantiate `register_ray`, which registers Ray as a `joblib` backend for `scikit-learn`:  \n",
    "```python\n",
    "import joblib\n",
    "from ray.util.joblib import register_ray\n",
    "register_ray()\n",
    "```\n",
    "\n",
    "Then run your original `scikit-learn` code within a Ray/`joblib` backend:\n",
    "```python\n",
    "with joblib.parallel_backend('ray'):\n",
    "    # original scikit-learn code\n",
    "```\n",
    "\n",
    "For example, here's some parallel hyperparameter tuning:\n",
    "```python\n",
    "import joblib\n",
    "from ray.util.joblib import register_ray\n",
    "register_ray()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "digits = load_digits()\n",
    "param_space = {\n",
    "    'C': np.logspace(-6, 6, 30),\n",
    "    'gamma': np.logspace(-8, 8, 30),\n",
    "    'tol': np.logspace(-4, -1, 30),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "model = SVC(kernel='rbf')\n",
    "search = sklearn.model_selection.RandomizedSearchCV(\n",
    "    model, param_space, cv=5, n_iter=300, verbose=10)\n",
    "\n",
    "with joblib.parallel_backend('ray'):\n",
    "    search.fit(digits.data, digits.target)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16793ada-97bd-4723-b225-bce2c1d24fd6",
   "metadata": {},
   "source": [
    "When finished, remember to shut down the Ray connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636be3a3-28d6-4663-8a78-fb8292b27223",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebccf4-2bc3-4fbc-97b9-8ce74fa30698",
   "metadata": {},
   "source": [
    "Please see this [repository](https://github.com/lukeconibear/distributed_deep_learning) for examples of how to do distributed deep learning using Ray Train with TensorFlow, PyTorch, and Horovod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380cf30b-7eec-4d87-9dc2-1ae4c480cfb2",
   "metadata": {},
   "source": [
    "## [Dask on Ray](https://docs.ray.io/en/latest/data/dask-on-ray.html)\n",
    "Use Ray as a backend for Dask tasks.  \n",
    "Dask dispatches tasks to Ray for scheduling and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc0ae7b-4d26-4410-aec6-fc104f8a8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import dask\n",
    "import dask.dataframe as dd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ray.util.dask import ray_dask_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a8ef39-65df-45ca-b26e-9b539cc523ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '129.11.87.102',\n",
       " 'raylet_ip_address': '129.11.87.102',\n",
       " 'redis_address': '129.11.87.102:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-12-20_11-47-12_888567_25572/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-12-20_11-47-12_888567_25572/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2021-12-20_11-47-12_888567_25572',\n",
       " 'metrics_export_port': 63246,\n",
       " 'node_id': 'e37649cbb30caaafbcfb5fdbe4645c1e07fbbc9c2a044468ebf0a02d'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler=ray_dask_get) \n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4eba7-acfb-4aff-b525-c4d9e8022689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0, 100, size=(2**10, 2**8)))\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5359569-5cf9-4adf-b0ae-e63a9564cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2abd54-2404-4fa3-8042-a3ca772f949f",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c97e49-4137-4cc7-ba53-1dd42feb7084",
   "metadata": {},
   "source": [
    "## Further information\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [Modin](https://modin.readthedocs.io/en/latest/)\n",
    "  - Swap out the library import and use the same API.\n",
    "  - Uses Ray or Dask to easily speed up your Pandas code.  \n",
    "To use Modin, simply replace the import and use Pandas API as normal.\n",
    "- [Mars](https://docs.pymars.org/en/latest/)\n",
    "  - A tensor-based unified framework for large-scale data computation which scales numpy, pandas, scikit-learn and many other libraries.\n",
    "  - Swap out the library import, use the same API, and add `.execute()`.\n",
    "  - [Mars Tensor](https://docs.pymars.org/en/latest/getting_started/tensor.html) for NumPy.  \n",
    "  - [Mars DataFrame](https://docs.pymars.org/en/latest/getting_started/dataframe.html) for Pandas.\n",
    "  - Mars can also use Ray as the backend ([instructions](https://docs.ray.io/en/latest/data/mars-on-ray.html)).\n",
    "- [Polars](https://www.pola.rs/)\n",
    "  - Lightning-fast DataFrame library for Rust and Python.\n",
    "- [RayDP](https://docs.ray.io/en/latest/data/raydp.html)\n",
    "  - Combines your Spark and Ray clusters, making it easy to do large scale data processing using the PySpark API and seemlessly use that data to train your models using TensorFlow and PyTorch.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Using IPython for parallel computing](https://ipyparallel.readthedocs.io/en/latest/)\n",
    "- [Concurrency](https://youtu.be/18B1pznaU1o) can also run different tasks together, but work is not done at the same time ([concurrency from the ground up](https://youtu.be/MCs5OvhV9S4)).   \n",
    "- [Asynchronous](https://youtu.be/iG6fr81xHKA) (multi-threading), useful for massive scaling, threads controlled explicitly.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
