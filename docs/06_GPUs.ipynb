{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8eda9a1-0b12-40da-836e-96f0cebf1b25",
   "metadata": {},
   "source": [
    "# GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c16cb6-0cba-4fda-acf4-03b9a791df9a",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/swd6_hpp/blob/main/docs/07_GPUs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c417818-9ff3-42f3-8e45-453b9a8e1c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "GPUs (Graphics Processing Units) are optimised for numerical operations, while CPUs (central processing units) perform general computation.\n",
    "\n",
    "GPU hardware is designed for data parallelism, where high throughputs are achieved when the GPU is computing the same operations on many different elements at once.\n",
    "\n",
    "Could use other types of accelerators too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0279a4-f16a-4838-b477-cb29e3fa222f",
   "metadata": {},
   "source": [
    "## [JAX](https://jax.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d30fc-c48f-4e05-a479-4659170ba0b4",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad1338-41dc-4178-b825-6895429e03fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc8033c1-a474-4acc-a389-7a42f9547c0b",
   "metadata": {},
   "source": [
    "## Automatic detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8b804-2628-4ada-863a-e8ad3693b5aa",
   "metadata": {},
   "source": [
    "Many libraries can use GPUs automatically if they can detect one.\n",
    "\n",
    "[`TensorFlow`](https://www.tensorflow.org/install/gpu)\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "```\n",
    "\n",
    "[`PyTorch`](https://pytorch.org/docs/stable/notes/cuda.html)\n",
    "```python\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66de92-f1d9-40d9-8030-f6940348aaef",
   "metadata": {},
   "source": [
    "## [CUDA](https://developer.nvidia.com/how-to-cuda-python) (Compute Unified Device Architecture)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3329e-6d98-4232-844b-dc3708e7617d",
   "metadata": {},
   "source": [
    "### [Numba](https://numba.pydata.org/numba-doc/latest/index.html)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18986b35-ae89-4e44-a288-1fa2465adf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac7641",
   "metadata": {},
   "source": [
    "Numba [`@vectorize`](https://numba.pydata.org/numba-doc/latest/user/vectorize.html) on the CPU\n",
    "- Can also use [`@jit`](https://numba.readthedocs.io/en/stable/user/jit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b80d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def do_maths(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db7324",
   "metadata": {},
   "source": [
    "Numba [`@vectorize`](https://numba.pydata.org/numba-doc/latest/user/vectorize.html) on the GPU\n",
    "- Can also use [`@cuda.jit`](https://numba.readthedocs.io/en/stable/cuda/kernels.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f458b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the GPU, need: types output(inputs) and target \n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def do_maths(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1f53f",
   "metadata": {},
   "source": [
    "Considerations and more information:\n",
    "- Ensure inputs are not too small and the calculation is not too simple.\n",
    "- Consider whether the calculation is worth the overhead of sending data to and from the GPU ([memory management](https://numba.pydata.org/numba-doc/dev/cuda/memory.html)).\n",
    "- Working with arrays of different dimensions: can use [generalized ufuncs](https://numpy.org/doc/stable/reference/c-api/generalized-ufuncs.html) (NumPy), implemented in Numba as `guvectorize` on [CPUs](http://numba.pydata.org/numba-doc/latest/user/vectorize.html#the-guvectorize-decorator) and [GPUs](http://numba.pydata.org/numba-doc/latest/cuda/ufunc.html#generalized-cuda-ufuncs).\n",
    "- What data precision is required (i.e., is 64-bit needed?).\n",
    "- Custom functions beyond ufuncs ([kernels](https://numba.pydata.org/numba-doc/dev/cuda/kernels.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b679d8-1df4-4cbb-a7ad-161e8ea4658d",
   "metadata": {},
   "source": [
    "## [RAPIDS](https://developer.nvidia.com/rapids)\n",
    "Accelerated data science libraries.\n",
    "- Arrays and matrices:\n",
    "  - [cuPy](https://cupy.dev/) for NumPy and SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52016c4b-e769-4a0d-ae9a-a223bc352f89",
   "metadata": {},
   "source": [
    "### [cuPy](https://cupy.dev/)\n",
    "\n",
    "```python\n",
    "# NumPy for CPU\n",
    ">>> import numpy as np\n",
    ">>> x_cpu = np.zeros((10, ))\n",
    ">>> y_cpu = np.zeros((10, 5))\n",
    ">>> z_cpu = np.dot(x_cpu, y_cpu)\n",
    ">>> z_cpu = cp.asnumpy(z_gpu) # convert over\n",
    "\n",
    "# CuPy for GPU\n",
    ">>> import cupy as cp\n",
    ">>> x_gpu = cp.zeros((10, ))\n",
    ">>> y_gpu = cp.zeros((10, 5))\n",
    ">>> z_gpu = cp.dot(x_gpu, y_gpu)\n",
    ">>> z_gpu = cp.asarray(z_cpu) # convert over\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb3717-1976-4ea1-b440-eeb6de205b7c",
   "metadata": {},
   "source": [
    "- Tabular data\n",
    "  - [cuDF](https://docs.rapids.ai/api/cudf/stable/) for Pandas\n",
    "- Machine learning\n",
    "  - [cuML](https://docs.rapids.ai/api/cuml/stable/) for scikit-learn\n",
    "  - [XGBoost](https://rapids.ai/xgboost.html) on GPUs\n",
    "- Graphs and networks\n",
    "  - [cuGraph](https://docs.rapids.ai/api/cugraph/stable/) for [NetworkX](https://networkx.org/)\n",
    "- Multiple GPUs\n",
    "  - [Dask with CUDA](https://rapids.ai/dask.html), cuDF, cuML, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210104b-8e88-4ad5-941b-c4a58fc97589",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea113ee0-9ed3-4b77-9f5f-eca6600f7d22",
   "metadata": {},
   "source": [
    "## Further information\n",
    "\n",
    "### Other options\n",
    "\n",
    "- ...\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [CuPy - Sean Farley](https://www.youtube.com/watch?v=_AKDqw6li58), PyBay 2019.  \n",
    "- [cuDF - Mark Harris](https://www.youtube.com/watch?v=lV7rtDW94do), PyCon AU 2019.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
